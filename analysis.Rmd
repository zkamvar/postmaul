---
title: "GitHub Analysis"
author: "Zhian N. Kamvar"
date: "3/30/2020"
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

The source for all the repositories is located at <https://carpentries.github.io/curriculum-feed/carpentries_lessons.json>. To 
avoid having to pull from it multiple times I'm going to set up a folder:

```{r packages}
library("fs")       # Filesystem navigation
library("jsonlite") # parsing JSON files
library("purrr")    # handling lists (JSON files)
library("dplyr")    # handling data frames and magic
library("tidyr")    # separating values
library("ggplot2")  # visualization
library("forcats")  # ordering factors
library("magrittr") # for the %T>% pipe I love so well
library("gh")       # accessing GitHub's API
library("polite")   # being respectful when downloading files
library("here")     # so I can always remember where I started
```


```{r data}
raw_data <- here::here("data", "raw")
raw_lessons <- fs::path(raw_data, "carpentries_lessons.json")
if (fs::file_exists(raw_lessons)) {
  
} else {
  fs::dir_create(raw_data)
  res <- download.file(
    url = "https://carpentries.github.io/curriculum-feed/carpentries_lessons.json",
    destfile = raw_lessons
  )
  if (res == 0L) {
    fs::file_chmod(raw_lessons, "a-wx")
  }
}

lessons <- read_json(raw_lessons, simplifyVector = FALSE) %>%
  purrr::map_dfr(.f = dplyr::as_tibble) %>%
  dplyr::mutate_if(is.character, 
    ~dplyr::if_else(. == "NA", as.character(NA), .)) %>%
  dplyr::mutate(life_cycle = forcats::fct_relevel(life_cycle,
      "pre-alpha", "alpha", "beta", "stable", "on-hold", "deprecated"
    )) %>%
  dplyr::mutate(life_cycle = forcats::fct_explicit_na(life_cycle)) %>%
  print()
```

# First look at available lessons

I'm going to take a look at all of the software carpentry lessons first. There
are currently `r nrow(lessons)` available lessons, but they are in different
stages of completion:

```{r lesson vis}
ggplot(lessons, aes(y = life_cycle, fill = curriculum)) +
  geom_bar(orientation = "y")
```

Let's inspect the ones that are stable and then look at the ones that are lower
down, first we should filter for those that are stable and actually have GitHub
URLs:

```{r stable}
stable <- lessons %>% filter(
  life_cycle == "stable", 
  curriculum != "instructor-training",
  !is.na(curriculum), # these are template repositories
  !is.na(URL)         # no GitHub URL is not very useful for me
)
stable
```

I end up with `r nrow(stable)` repositories to play with:

```{r curriculum-language}
ggplot(stable, aes(y = curriculum, fill = language)) +
  geom_bar(orientation = "y")
```

# Inspection of repository features

I will use the {gh} package to inspect the features of each repository:

 - tags
 - directory structure
 - dependencies

I can use the GitHub API to get the contents of the repositories:
<https://developer.github.com/v3/repos/contents/#get-contents>. The {gh} package
allows me to write the responses to disk so that I don't have to query every 
time I want to re-run the analysis. If I wanted to do this with fresh data, all
I would need to do is to clear the data folder.

One of the tripping points here is that not all of the repositories will have
`_episodes_rmd/` directories, so I will need to walk over these with
`purrr::possibly()`, a nice little failsafe function.


```{r get_rmd_episodes}
safegh <- purrr::possibly(gh::gh, otherwise = list(NA))

rmd_episodes <- function(owner, repo) {
  safegh <- purrr::slowly(
    f    = purrr::possibly(gh::gh, otherwise = list(NA)),
    rate = rate_delay(pause = 2)
  )
  OR <- glue::glue("{owner}--{repo}")
  safegh("/repos/:owner/:repo/contents/_episodes_rmd", 
    owner = owner, 
    repo = repo, 
    .destfile = here::here(fs::path("data", "rmd_JSON", OR, ext = "json"))
  )
}

has_rmd <- stable %>%
  tidyr::separate(URL, into = c(NA, NA, NA, "user", NA), sep = "/", remove = FALSE) %>%
  mutate(user = purrr::walk2(.x = user, .y = repository, .f = rmd_episodes)) %>%
  mutate(JSON = purrr::map2(.x = user, .y = repository,
    .f = ~jsonlite::read_json(
      here::here("data", "rmd_JSON", glue::glue("{.x}--{.y}.json"))
    )
  )) %>%
  filter(lengths(JSON) > 2)
```

After parsing, we find that we have RMarkdown files for a grand total of `r nrow(has_rmd)`:

```{r rmd_episodes_repos}
all_rmd_files <- has_rmd %>%
  select(user, repository, URL, JSON) %T>%
  print() %>%
  unnest(JSON) %>%
  unnest_wider(JSON) %>%
  filter(!grepl("^\\.git", name))

download_r_file <- purrr::slowly(function(user, repo, name, url) {
  dir <- fs::dir_create(here::here("data", "r-files", user, repo))
  if (fs::file_exists(fs::path(dir, name))) {
    # no need
    0
  } else {
    download.file(
      url = url,
      destfile = fs::path(dir, name)
    )
  }
}, rate = purrr::rate_delay(pause = 2))


all_rmd_files %>%
  select(name, download_url) %>%
  knitr::kable()

all_rmd_files %>%
  mutate(result = pmap_chr(list(user, repository, name, download_url), download_r_file))
```


# Session Information

```{r sessioninfo}
sessioninfo::session_info()
```

