---
title: "GitHub Analysis"
author: "Zhian N. Kamvar"
date: "3/30/2020"
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

The source for all the repositories is located at <https://carpentries.github.io/curriculum-feed/carpentries_lessons.json>. To 
avoid having to pull from it multiple times I'm going to set up a folder:

```{r packages}
library("fs")       # Filesystem navigation
library("jsonlite") # parsing JSON files
library("purrr")    # handling lists (JSON files)
library("dplyr")    # handling data frames and magic
library("tidyr")    # separating values
library("ggplot2")  # visualization
library("forcats")  # ordering factors
library("magrittr") # for the %T>% pipe I love so well
library("gh")       # accessing GitHub's API
library("polite")   # being respectful when downloading files
library("here")     # so I can always remember where I started
library("pegboard") # parsing and analysis of carpentries episodes
library("git2r")    # downloading github repositories
library("waldo")    # comparing objects
```


```{r data}
raw_data <- here::here("data", "raw")
raw_lessons <- fs::path(raw_data, "carpentries_lessons.json")
if (fs::file_exists(raw_lessons)) {
  
} else {
  fs::dir_create(raw_data)
  res <- download.file(
    url = "https://carpentries.github.io/curriculum-feed/carpentries_lessons.json",
    destfile = raw_lessons
  )
  if (res == 0L) {
    fs::file_chmod(raw_lessons, "a-wx")
  }
}

lessons <- read_json(raw_lessons, simplifyVector = FALSE) %>%
  purrr::map_dfr(.f = dplyr::as_tibble) %>%
  dplyr::mutate_if(is.character, 
    ~dplyr::if_else(. == "NA", as.character(NA), .)) %>%
  dplyr::mutate(life_cycle = forcats::fct_relevel(life_cycle,
      "pre-alpha", "alpha", "beta", "stable", "on-hold", "deprecated"
    )) %>%
  dplyr::mutate(life_cycle = forcats::fct_explicit_na(life_cycle)) %>%
  print()
```

# First look at available lessons

I'm going to take a look at all of the software carpentry lessons first. There
are currently `r nrow(lessons)` available lessons, but they are in different
stages of completion:

```{r lesson vis}
ggplot(lessons, aes(y = life_cycle, fill = curriculum)) +
  geom_bar(orientation = "y")
```

Let's inspect the ones that are stable and then look at the ones that are lower
down, first we should filter for those that are stable and actually have GitHub
URLs:

```{r stable}
stable <- lessons %>% filter(
  life_cycle == "stable", 
  curriculum != "instructor-training",
  !is.na(curriculum), # these are template repositories
  !is.na(URL)         # no GitHub URL is not very useful for me
)
stable
```

I end up with `r nrow(stable)` repositories to play with:

```{r curriculum-language}
ggplot(stable, aes(y = curriculum, fill = language)) +
  geom_bar(orientation = "y")
```

# Inspection of repository features

I will use the {gh} package to inspect the features of each repository:

 - tags
 - directory structure
 - dependencies

I can use the GitHub API to get the contents of the repositories:
<https://developer.github.com/v3/repos/contents/#get-contents>. The {gh} package
allows me to write the responses to disk so that I don't have to query every 
time I want to re-run the analysis. If I wanted to do this with fresh data, all
I would need to do is to clear the data folder.

One of the tripping points here is that not all of the repositories will have
`_episodes_rmd/` directories, so I will need to walk over these with
`purrr::possibly()`, a nice little failsafe function.


```{r get_rmd_episodes}
safegh <- purrr::possibly(gh::gh, otherwise = list(NA))

rmd_episodes <- function(owner, repo) {
  safegh <- purrr::slowly(
    f    = purrr::possibly(gh::gh, otherwise = list(NA)),
    rate = rate_delay(pause = 2)
  )
  OR <- glue::glue("{owner}--{repo}")
  safegh("/repos/:owner/:repo/contents/_episodes_rmd", 
    owner = owner, 
    repo = repo, 
    .destfile = here::here(fs::path("data", "rmd_JSON", OR, ext = "json"))
  )
}

vorhees <- purrr::possibly(jsonlite::read_json, otherwise = list())

lesson_has_rmd <- . %>%
  tidyr::separate(URL, into = c(NA, NA, NA, "user", NA), sep = "/", remove = FALSE) %>%
  mutate(user = purrr::walk2(.x = user, .y = repository, .f = rmd_episodes)) %>%
  mutate(JSON = purrr::map2(.x = user, .y = repository,
    .f = ~vorhees(
      here::here("data", "rmd_JSON", glue::glue("{.x}--{.y}.json"))
    )
  )) %>%
  filter(lengths(JSON) > 2)
has_rmd <- stable %>% lesson_has_rmd
has_rmd_all <- lessons %>% 
  lesson_has_rmd %>% 
  filter(repository != "lesson-example") %>%
  arrange(life_cycle)
```

After parsing, we find that we have RMarkdown files for a grand total of 
`r nrow(has_rmd_all)` lessons and `r nrow(has_rmd)` stable lessons. From here,
we can grab these lessons to see if we can build them with our docker container.


The command to use is:

```bash
docker run --rm -it -e USER=$(id -u) -e GROUP=$(id -g) -v ${PWD}:/home/rstudio rocker/verse:4.0.0 make -C /home/rstudio lesson-md
```


Let's download these repos:

```{r rmd_episodes_repos}
rmdpath <- path("data", "rmd-repos")
if (!dir_exists(rmdpath)) {
  dir_create(path = rmdpath)
}
g <- function(u, r, path = rmdpath) {
  URL <- glue::glue("https://github.com/{u}/{r}.git")
  path <- glue::glue("{path}/{u}--{r}")
  if (fs::dir_exists(path)) {
    git2r::pull(repo = path)
  } else {
    git2r::clone(URL, local_path = path)
  }
}
purrr::walk2(has_rmd_all$user, has_rmd_all$repository, g, rmdpath) 
```

Now all the repos have been downloaded, we can render the episodes under
different versions of R and see how they go. Note that I have to use the
geospatial R container in order to get things to work properly.

```{r dokken, results = "hide"}

run_docker <- function(the_path, R_VERSION) {
  docker_run <- "docker run --rm -it -v {the_path}:/home/rstudio"
  contai_ner <- "rocker/geospatial:{R_VERSION} make -C /home/rstudio lesson-md"
  system(glue::glue("cd {the_path}; git clean -fd .; git checkout -- ."))
  system(glue::glue("rm -rf {the_path}/_episodes/*"))
  system(glue::glue("{glue::glue(docker_run)} {glue::glue(contai_ner)}"))
}

dockin <- function(u, r) {

  pth <- glue::glue("{u}--{r}")
  the_path <- fs::path_abs(fs::path("data", "rmd-repos", pth))

  # Run with R 3.6.3 ---------------------------
  run_docker(the_path, "3.6.3")
  r3 <- try(Lesson$new(the_path, rmd = FALSE))

  # Run with R 4.0.0 ---------------------------
  run_docker(the_path, "4.0.0")
  r4 <- try(Lesson$new(the_path, rmd = FALSE))

  system(glue::glue("cd {the_path}; git clean -fd .; git checkout -- ."))


  list(r3, r4)

}

res <- purrr::map2(has_rmd_all$user, has_rmd_all$repository, dockin)
```

We can iterate and compare:

```{r}
cmpr <- function(lesson) {

  if (!inherits(lesson[[1]], "Lesson")) {
    return(NULL)
  }
  otag    <- ".//self::d1:code_block[@ktag='{: .output}']"
  o1 <- map(lesson[[1]]$episodes, ~.x$code %>% xml2::xml_find_all(otag) %>% xml2::xml_text())
  o2 <- map(lesson[[2]]$episodes, ~.x$code %>% xml2::xml_find_all(otag) %>% xml2::xml_text())
  for (i in length(o1)) {
    
    message(glue::glue("Lesson: {basename(lesson[[1]]$path)}  Episode: {basename(lesson[[1]]$files[i])}"))
    print(waldo::compare(o1[[i]], o2[[i]]))
  }
}

purrr::walk(res, cmpr)
```


# Session Information

```{r sessioninfo}
sessioninfo::session_info()
```


